# -*- coding: utf-8 -*-
"""klasifikasi gambar fix bgt fr skrg

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H39i9nGJP5YMRQLU3aN2u54I-nqvpNCA

# Proyek Klasifikasi Gambar: Cats And Dogs Classification Dataset
- **Nama:** Aditya Chandra Nugraha
- **Email:** m014d5y0051@student.devacademy.id
- **ID Dicoding:** m014d5y0051

Dataset Klasifikasi Kucing dan Anjing adalah dataset visi komputer standar yang mengklasifikasi foto sebagai anjing atau kucing. Dataset ini disediakan sebagai subset foto dari dataset yang jauh lebih besar, sekitar 25 ribu foto.

Dataset berisi 24.998 gambar , dibagi menjadi 12.499 gambar Kucing dan 12.499 gambar Anjing . Gambar latih dibagi rata antara gambar kucing dan anjing, sementara gambar uji tidak diberi label. Hal ini memungkinkan pengguna untuk mengevaluasi model mereka pada data yang belum terlihat.

## Import Semua Packages/Library yang Digunakan
"""

pip freeze > requirement.txt

pip install tensorflow

#library untuk ngolah dataset
import pandas as pd
import numpy as np
#library visualisasi
import matplotlib.pyplot as plt
import seaborn as sns
#library untuk bangun model deep learning
import tensorflow as tf
import keras
from keras import Model, layers
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from keras.models import Sequential, Model
from keras.layers import InputLayer, Dense, Flatten, Dropout, Conv2D, SeparableConv2D, MaxPool2D, BatchNormalization
from keras.optimizers import Adam, RMSprop, SGD

#import library untuk langkah ML
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report

#library utk pemrosesan data gambar
import skimage
import cv2
from skimage.transform import resize, rotate, warp, AffineTransform
from skimage import io
from skimage import img_as_ubyte
from skimage.exposure import adjust_gamma
from skimage.util import random_noise
from PIL import Image
import random
from tqdm.notebook import tqdm as tq #untuk menampilkan bar progres saat iterasi.


#library untuk keperluan download dataset dan manipulasi file
import os
import shutil
import kagglehub
from pathlib import Path
from google.colab import files

print(tf.__version__)

"""### Data Loading"""

files.upload()

# 1️⃣ Make the kaggle folder (if it doesn’t exist)
!mkdir -p ~/.kaggle

# 2️⃣ Copy your kaggle.json file from the current directory into that folder
!cp kaggle.json ~/.kaggle/

# 3️⃣ Set proper file permissions
!chmod 600 ~/.kaggle/kaggle.json

# 4️⃣ Download your dataset from Kaggle
!kaggle datasets download -d bhavikjikadara/dog-and-cat-classification-dataset

# 5️⃣ Unzip the downloaded file
!unzip dog-and-cat-classification-dataset.zip

"""## Data Preparation"""

path_gambar = Path('/content/PetImages')
CAT_DIR = path_gambar + "/Cat"
DOG_DIR = path_gambar + "/Dog"
# data sudah terpisah kedalam kelasnya masing-masing dalam dataset

#Data Checking

def check_gambar():
  gambar_emosi = {}

  for i in os.listdir(path_gambar):
    gambar_emosi[i] = os.listdir(os.path.join(path_gambar, i))

  fig, axs = plt.subplots(len(gambar_emosi.keys()), 5, figsize=(15, 15))

  for i, class_name in enumerate(os.listdir(path_gambar)):
      images = np.random.choice(gambar_emosi[class_name], 5, replace=False)

      for j, image_name in enumerate(images):
          img_path = os.path.join(path_gambar, class_name, image_name)
          img = Image.open(img_path).convert("L")  # Konversi menjadi skala keabuan
          axs[i, j].imshow(img, cmap='gray')
          axs[i, j].set(xlabel=class_name, xticks=[], yticks=[])


  fig.tight_layout()
check_gambar()

file_name = []
labels = []
full_path = []

# Dapatkan nama file gambar, path file, dan label satu per satu dengan looping, dan simpan sebagai dataframe
def plot_jumlah_gambar(p):
  for path, subdirs, files in os.walk(p):
      for name in files:
          full_path.append(os.path.join(path, name))
          labels.append(path.split('/')[-1])
          file_name.append(name)

  distribution_train = pd.DataFrame({"path":full_path, 'file_name':file_name, "labels":labels})

  # Plot distribusi gambar di setiap kelas
  Label = distribution_train['labels']
  plt.figure(figsize = (6,6))
  sns.set_style("darkgrid")
  plot_data = sns.countplot(Label)

plot_jumlah_gambar(path_gambar)

"""### Data Preprocessing"""

#fungsi-fungsi augmentasi
# Membuat fungsi untuk melakukan rotasi berlawanan arah jarum jam
def rotasi1(gambar):
    gambar = cv2.cvtColor(gambar, 0)
    gambar = cv2.resize(gambar, (224,224))
    sudut = random.randint(0,180)
    return rotate(gambar, sudut)

# Membuat fungsi untuk melakukan rotasi searah jarum jam
def rotasi2(gambar):
    gambar = cv2.cvtColor(gambar, 0)
    gambar = cv2.resize(gambar, (224,224))
    sudut = random.randint(0,180)
    return rotate(gambar, -sudut)

# Membuat fungsi untuk membalik gambar secara vertikal dari atas ke bawah
def balik(gambar):
    gambar = cv2.cvtColor(gambar, 0)
    gambar = cv2.resize(gambar, (224,224))
    return np.flipud(gambar)

# Membuat fungsi untuk memberikan efek peningkatan kecerahan pada gambar
def terangin(gambar):
    gambar = cv2.cvtColor(gambar, 0)
    gambar = cv2.resize(gambar, (224,224))
    gambar = adjust_gamma(gambar, gamma=0.5,gain=1)
    return gambar

# Membuat fungsi untuk memberikan efek blur pada gambar
def blur(gambar):
    gambar = cv2.cvtColor(gambar, 0)
    gambar = cv2.resize(gambar, (224,224))
    return cv2.GaussianBlur(gambar, (9,9),0)

# Membuat fungsi untuk memberikan efek pergeseran acak pada gambar
def geser(gambar):
    gambar = cv2.cvtColor(gambar, 0)
    gambar = cv2.resize(gambar, (224,224))
    transform = AffineTransform(shear=0.2)
    shear_image = warp(gambar, transform, mode="wrap")
    return shear_image

# Membuat fungsi untuk melakukan pergeseran melengkung pada gambar
def warp_shift(gambar):
    gambar = cv2.cvtColor(gambar, 0)
    gambar = cv2.resize(gambar, (224,224))
    transform = AffineTransform(translation=(0,40))
    warp_image = warp(gambar, transform, mode="wrap")
    return warp_image

augmentasi = {  'rotate anticlockwise': rotasi1,
                'rotate clockwise': rotasi2,
                'warp shift': warp_shift,
                'blurring image': blur,
                'add brightness' : terangin,
                'flip up down': balik,
                'shear image': geser
}

folder_aug = [
    '/content/PetImages/Cat',
    '/content/PetImages/Dog'

]

def generate_aug_img(path):
    if 'happy' in path.lower():
        print(f"Skipping augmentation for {path}")
        return

    gambar_augmented = [
        os.path.join(path, im)
        for im in os.listdir(path)
        if im.lower().endswith(('.jpg', '.jpeg', '.png'))
    ]

    jmlh = 90
    i = 1
    while i <= jmlh:
        img_random = random.choice(gambar_augmented)
        try:
          original_image = io.imread(img_random)
          transformed_image = original_image.copy()
          transformation_count = random.randint(1, len(augmentasi))

          for _ in range(transformation_count):
              key = random.choice(list(augmentasi))
              transformed_image = augmentasi[key](transformed_image)

          # Convert to uint8 if needed
          if transformed_image.dtype == 'float64':
              transformed_image = (transformed_image * 255).astype('uint8')
          elif transformed_image.dtype == 'float32':
              transformed_image = (transformed_image * 255).astype('uint8')

          base_name = os.path.basename(img_random).split('.')[0]
          new_image_path = os.path.join(path, f"augmented_{base_name}_{i}.jpg")

          cv2.imwrite(new_image_path, transformed_image)
          i += 1

        except Exception as e:
          print(f"Skipping image {img_random}: {e}")
    gambar_augmented.clear()

# Apply to all folders
for folder in folder_aug:
    print(f"Augmenting images in {folder} ...")
    generate_aug_img(folder)

plot_jumlah_gambar(path_gambar)

# fungsi untuk memfilter gambar yang rusak
cat_files = sorted(str(p) for p in CAT_DIR.glob("*.jpg"))
dog_files = sorted(str(p) for p in DOG_DIR.glob("*.jpg"))

def filter_image(pathImg):
  valid_img = []

  for i in pathImg:
    try:
      with Image.open(i) as img:
        img.verify()
      valid_img.append(i)
    except Exception as e:
      if len(valid_img) % 500 == 0:
        print("gabisa")
  return valid_img

cat_files = filter_image(cat_files)
dog_files = filter_image(dog_files)

"""#### Split Dataset"""

labels_cat = [0] * len(cat_files)  # 0 = Cat
labels_dog = [1] * len(dog_files)  # 1 = Dog

X = np.array(cat_files + dog_files)
y = np.array(labels_cat + labels_dog)

# Stratified split

X_train, X_dummy, y_train, y_dummy = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

X_val, y_val, X_test, y_test = train_test_split(
    X_dummy, y_dummy, test_size = 0.2, random_state= 42
)

len(X_train), len(X_val), len(X_test), y_train.mean(), y_val.mean(), y_test.mean()

AUTOTUNE  = tf.data.AUTOTUNE
def safe_decode_image(path):
  try:
    img_bytes = tf.io.read_file(path.numpy().decode("utf-8"))
    img = tf.image.decode_image(img_bytes, channels=3, expand_animations=False)
    img = tf.image.convert_image_dtype(img, tf.float32)
    img.set_shape([None, None, 3])
    img = tf.image.resize(img, (224,224))
    return img
  except Exception:
    return tf.zeros((224,224) + (3,), dtype=tf.float32)

def load_and_preprocess(path, label):
  img = tf.py_function(func=safe_decode_image, inp=[path], Tout=tf.float32)
  img.set_shape((224, 224) + (3,))  # re-assert static shape
  return img, label

def make_dataset(paths, labels, training=False):
    ds = tf.data.Dataset.from_tensor_slices((paths, labels))
    if training:
        ds = ds.shuffle(buffer_size=min(len(paths), 10000), seed=42, reshuffle_each_iteration=True)
    ds = ds.map(load_and_preprocess, num_parallel_calls=AUTOTUNE)
    if training:
        # Data augmentation (light, efficient)
        aug = keras.Sequential([
            layers.RandomFlip("horizontal"),
            layers.RandomRotation(0.05),
            layers.RandomZoom(0.1),
        ])
        ds = ds.map(lambda x, y: (aug(x, training=True), y), num_parallel_calls=AUTOTUNE)
    ds = ds.batch(32).prefetch(AUTOTUNE)
    return ds

train_ds = make_dataset(X_train, y_train, training=True)
test_ds = make_dataset(X_test, y_test, training = True)
val_ds  = make_dataset(X_val,   y_val,   training=False)

"""## Modelling"""

Conv2Layer1 = Sequential([
    Conv2D(32, (3,3),padding='same', activation='relu', input_shape = (224, 224, 3)),
    BatchNormalization(),
    MaxPool2D(2,2)
])
Conv2Layer2 = Sequential([
    Conv2D(32, (4,4),padding='same', activation='relu'),
    BatchNormalization(),
    MaxPool2D(2,2)
])
Conv2Layer3 = Sequential([
    Conv2D(32, (7,7),padding='same', activation='relu'),
    BatchNormalization(),
    MaxPool2D(2,2)
])

myModel = Sequential([
    Conv2Layer1,
    Conv2Layer2,
    Conv2Layer3,
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(7, activation='sigmoid')
])

myModel.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-4),
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

myModel.summary()

base = keras.applications.MobileNetV2(
    input_shape= (224, 224) + (3,),
    include_top=False,
    weights="imagenet"
)
base.trainable = False  # start frozen

inputs = layers.Input(shape=(224, 224) + (3,))
# (If you skipped the earlier /255 scaling, you’d apply preprocess_input here)
x = inputs
x = base(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.2)(x)
outputs = layers.Dense(1, activation="sigmoid")(x)  # binary classification

model2 = keras.Model(inputs, outputs)
model2.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-4),
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

model2.summary()

ckpt_path = "/content/mobilenetv2_catsdogs.keras"

callbacks = [
    keras.callbacks.ModelCheckpoint(
        ckpt_path, monitor="val_accuracy", save_best_only=True, mode="max"
    ),
    keras.callbacks.EarlyStopping(
        monitor="val_loss", patience=3, restore_best_weights=True
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss", factor=0.5, patience=2, verbose=1
    ),
]

hist = myModel.fit(
    train_ds,test_ds,
    validation_data= val_ds,
    batch_size=32,
    epochs=30,
    callbacks=callbacks)

"""## Evaluasi dan Visualisasi"""

def plot_history(h):
    acc = h.history["accuracy"]; val_acc = h.history["val_accuracy"]
    loss = h.history["loss"];     val_loss = h.history["val_loss"]

    plt.figure(figsize=(6,4))
    plt.plot(acc, label="train acc")
    plt.plot(val_acc, label="val acc")
    plt.xlabel("Epoch"); plt.ylabel("Accuracy"); plt.legend(); plt.title("Accuracy"); plt.show()

    plt.figure(figsize=(6,4))
    plt.plot(loss, label="train loss")
    plt.plot(val_loss, label="val loss")
    plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.legend(); plt.title("Loss"); plt.show()

plot_history(hist)

val_images, val_labels = [], []
for batch_imgs, batch_labels in val_ds.unbatch().batch(256):
    val_images.append(batch_imgs)
    val_labels.append(batch_labels)
val_images = tf.concat(val_images, axis=0)
val_labels = tf.concat(val_labels, axis=0).numpy().astype(int)

val_probs = model.predict(val_images, verbose=0).ravel()
val_preds = (val_probs >= 0.5).astype(int)

print(classification_report(val_labels, val_preds, target_names=["Cat","Dog"]))

matriks = confusion_matrix(val_labels, val_preds)
plt.figure(figsize=(4,4))
plt.imshow(matriks)

plt.xticks([0,1], ["Cat","Dog"])
plt.yticks([0,1], ["Cat","Dog"])
for i in range(2):
    for j in range(2):
        plt.text(j, i, matriks[i, j], ha="center", va="center")
plt.xlabel("Predicted"); plt.ylabel("True")
plt.show()

"""## Konversi Model"""

# Simpan model ke format SavedModel
myModel.save("/content/saved_model_cat_dog_classifier")

print("✅ Model saved in TensorFlow SavedModel format!")

# Konversi ke TF-Lite
converter = tf.lite.TFLiteConverter.from_saved_model("/content/saved_model_cat_dog_classifier")
tflite_model = converter.convert()

# Simpan file .tflite
with open("/content/facial_emotion_model.tflite", "wb") as f:
    f.write(tflite_model)

print("✅ Model saved in TensorFlow Lite format!")

pip install tensorflowjs

import tensorflowjs as tfjs

tfjs_target_dir = "/content/tfjs_model_cat_dog_classifier"
tfjs.converters.save_keras_model(myModel, tfjs_target_dir)

print("✅ Model saved in TensorFlow.js format!")

"""## Inference (Optional)"""

